{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddnn.data import *\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "%matplotlib ipympl\n",
    "\n",
    "\n",
    "dataset_type = \"\"\n",
    "epochs = 500\n",
    "torch.manual_seed(123)\n",
    "if isinstance(dataset_type, tuple):\n",
    "    traindata = read_monks(dataset_type[1], \"train\")\n",
    "    traindata = onehot_encoding(data=traindata)\n",
    "\n",
    "    testdata = read_monks(dataset_type[1], \"test\")\n",
    "    testdata = onehot_encoding(data=testdata)\n",
    "else:\n",
    "    traindata = read_ML_cup(\"train\")\n",
    "    traindata, testdata = train_valid_split(traindata)\n",
    "    blindtest = read_ML_cup(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(traindata.data.shape[1], 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, traindata.labels.shape[1]),\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-3)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Converting inputs and labels to Variable\n",
    "inputs = torch.tensor(traindata.data, dtype=torch.float32)\n",
    "labels = torch.tensor(traindata.labels, dtype=torch.float32)\n",
    "\n",
    "test = torch.tensor(testdata.data, dtype=torch.float32)\n",
    "testlabels = torch.tensor(testdata.labels, dtype=torch.float32)\n",
    "\n",
    "scores = []\n",
    "for epoch in range(epochs):\n",
    "    # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # get output from the model, given the inputs\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # get loss for the predicted output\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    test_loss = None\n",
    "    with torch.no_grad():\n",
    "        pred = model(test)\n",
    "        test_loss = criterion(pred, testlabels)\n",
    "\n",
    "    # get gradients w.r.t to parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    scores.append((loss.item(), test_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 plot with train and valid\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "def plot_results():\n",
    "    fig.tight_layout()\n",
    "    ax.clear()\n",
    "    ax.set_xlabel(\"epochs\")\n",
    "    ax.set_ylabel(loss)\n",
    "    for where, style in zip([0, 1], [None, \"dotted\"]):\n",
    "        y = [score[where] for score in scores]\n",
    "        if loss == \"binary_accuracy\":\n",
    "            # todo fix to show last not best\n",
    "            best = max(y)\n",
    "            form = \"{:.2}\"\n",
    "            logplot = False\n",
    "        else:\n",
    "            best = min(y)\n",
    "            form = \"{:.2E}\"\n",
    "            logplot = True\n",
    "        # scale to resemble number of epochs instead of plot points\n",
    "        ticks_x = ticker.FuncFormatter(lambda x, pos: \"{0:g}\".format(x))\n",
    "        ax.xaxis.set_major_formatter(ticks_x)\n",
    "        if logplot:\n",
    "            ax.set_yscale(\"log\")\n",
    "        else:\n",
    "            ax.set_yscale(\"linear\")\n",
    "        ax.plot(\n",
    "            y, label=f\"{where}: {form.format(best)}\", linestyle=style, color=\"black\"\n",
    "        )\n",
    "        ax.legend()\n",
    "\n",
    "\n",
    "plot_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:26:04) [GCC 10.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5bd504499a3d325a7c1da9f8228712639636db49ae66a9009fa19a793144457f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
