{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfe5980-4af2-481f-ad67-053eb47666a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet():\n",
    "    def __init__(layers, loss_function=\"MSE\"):\n",
    "        assert isinstance(layers, list)\n",
    "        assert (isinstance(layer, NeuralLayer) for layer in layers)\n",
    "        \n",
    "        self.layers = layers\n",
    "        self.loss, self.loss_gradient = get_loss_function(loss_function)\n",
    "        \n",
    "    def get_loss_function(self, string):\n",
    "        # to vectorize\n",
    "        if string == \"MSE\":\n",
    "            def MSE(pred, label):\n",
    "                # output = (x,y)\n",
    "                l = pred.shape[0]\n",
    "                sqe = 1/2* np.sum((label - pred)**2)\n",
    "                return sqe / l\n",
    "            def MSE_GRAD(pred, label):\n",
    "                return label - pred\n",
    "                \n",
    "            return (\n",
    "                MSE, # function\n",
    "                MSE_GRAD  # gradient\n",
    "            )\n",
    "        pass\n",
    "    \n",
    "    def __call__(data):\n",
    "        res = data\n",
    "        for layer in layers:\n",
    "            res = layer(res)\n",
    "        return res\n",
    "    \n",
    "    def backward():\n",
    "        pass\n",
    "        \n",
    "    def update_weights():\n",
    "        pass\n",
    "    \n",
    "    def zero_gradient():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e91ca9e-02a0-40a6-863e-bd8ddcdaa221",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_momentum_function(params):\n",
    "        if params[\"type\"] == \"None\":\n",
    "            return lambda x: 0\n",
    "        elif params[\"type\"] == \"original\":\n",
    "            return lambda x: params[\"alpha\"] * x\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid Momentum Type: {name}\")\n",
    "        \n",
    "    def get_regularization_function(name):\n",
    "        if params[\"type\"] == \"None\":\n",
    "            return lambda x: 0\n",
    "        elif params[\"type\"] == \"L2\":\n",
    "            return lambda x: params[\"lambda\"] * x\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid Regularization Type: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1956c2-6e64-4b16-87fd-2562bb658e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralLayer():\n",
    "    def __init__(\n",
    "        self, \n",
    "        shape : (int, int), \n",
    "        activation_function = \"ReLU\" : str,\n",
    "        momentum = {'type': \"original\", 'alpha': 0.5} : dict,\n",
    "        regularization = {'type': \"L2\", 'lambda': 0.5} : dict,\n",
    "    ):\n",
    "        self.weights = np.random.rand(shape)\n",
    "        self.biases = np.random.rand(shape[1])\n",
    "        self.activation, self.activation_gradient = get_activation_function(activation_function)\n",
    "        self.weights_gradient = np.empty(shape[::-1])\n",
    "        self.biases_gradient = np.empty(shape[1])\n",
    "        # self.momentum = get_momentum_function(momentum)\n",
    "        # self.regularization = get_regularization_function(regularization)\n",
    "        \n",
    "    def get_activation_function(name):\n",
    "        if name == \"ReLU\":\n",
    "            return (\n",
    "                lambda x: x*(x>0), # function\n",
    "                lambda x: 1*(x>0). # gradient\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid Activation Function: {name}\")\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        self.output_buffer = self.weights @ data\n",
    "        return self.activation(self.output_buffer)\n",
    "    \n",
    "    def backward(self, output_gradient):\n",
    "        self.biases_gradient[:] = output_gradient\n",
    "        self.weights_gradient[:] = output_gradient * self.activation(self.output_buffer)\n",
    "        input_gradient = (self.weights.T @ output_gradient) * self.activation_gradient(self.output_buffer)\n",
    "        return input_gradient\n",
    "        \n",
    "    def update_weights(self):\n",
    "        pass\n",
    "    \n",
    "    def zero_gradient(self):\n",
    "        self.biases_gradient[:] = 0\n",
    "        self.weights_gradient[:] = 0\n",
    "        self.output_buffer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc66449-2601-478d-9742-7f3626375cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
