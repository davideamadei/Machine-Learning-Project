{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5b06b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddnn.nn import *\n",
    "from ddnn.validation import *\n",
    "from ddnn.data import *\n",
    "\n",
    "estimator = Estimator(\n",
    "    net=NeuralNetwork(\n",
    "        [\n",
    "            LinearLayer((9, 32)),\n",
    "            ActivationFunction(\"tanh\"),\n",
    "            LinearLayer((32, 32)),\n",
    "            ActivationFunction(\"tanh\"),\n",
    "            LinearLayer((32, 2)),\n",
    "        ]\n",
    "    ),\n",
    "    loss=LossFunction(\"MSE\"),\n",
    "    # optimizer=Optimizer(\"SGD\", learning_rate=0.5, momentum_coefficient=0.5, l2_coefficient=0),\n",
    "    optimizer=Optimizer(\"Adam\", learning_rate=0.01, l2_coefficient=0.0033),\n",
    "    batchsize=-1,\n",
    "    initializer=Initializer(\"glorot_uniform\"),\n",
    "    seed=123,\n",
    ")\n",
    "early_stopping = 2.557191205025858\n",
    "epochs = 1500\n",
    "# dataset_type = (\"monk\", 2)\n",
    "dataset_type = \"ML_cup\"\n",
    "log_every = 1\n",
    "losses = [\"MSE\", \"MEE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff1b843",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(dataset_type, tuple):\n",
    "    traindata = read_monks(dataset_type[1], \"train\")\n",
    "    traindata = onehot_encoding(data=traindata)\n",
    "\n",
    "    testdata = read_monks(dataset_type[1], \"test\")\n",
    "    testdata = onehot_encoding(data=testdata)\n",
    "else:\n",
    "    traindata = read_ML_cup(\"train\")\n",
    "    traindata, testdata = train_valid_split(traindata, seed=123)\n",
    "    blindtest = read_ML_cup(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata.shape, testdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlogger = Logger(\n",
    "    estimator,\n",
    "    losses=losses,\n",
    "    training_set=traindata,\n",
    "    validation_set=testdata,\n",
    "    every=log_every,\n",
    ")\n",
    "if early_stopping is not None:\n",
    "    teststopper = TrainingThresholdStopping(estimator, early_stopping)\n",
    "\n",
    "    def callback(record):\n",
    "        testlogger(record)\n",
    "        teststopper(record)\n",
    "\n",
    "else:\n",
    "\n",
    "    def callback(record):\n",
    "        testlogger(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6d8d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.train(traindata, callback=callback, n_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = estimator.evaluate(losses=losses, dataset=traindata)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59993b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = estimator.evaluate(losses=losses, dataset=testdata)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from ipywidgets import interact\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "\n",
    "# 1 plot with train and valid\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "\n",
    "\n",
    "@interact(\n",
    "    loss=testlogger._losses,\n",
    ")\n",
    "def plot_results(loss):\n",
    "    fig1.tight_layout()\n",
    "    ax1.clear()\n",
    "    ax1.set_xlabel(\"epochs\")\n",
    "    ax1.set_ylabel(loss)\n",
    "    for where, style in zip([\"train\", \"valid\"], [None, \"dotted\"]):\n",
    "        y = testlogger._scores[0][\"folds\"][0][where][loss]\n",
    "        if loss == \"binary_accuracy\":\n",
    "            # todo fix to show last not best\n",
    "            best = max(y)\n",
    "            form = \"{:.2}\"\n",
    "            logplot = False\n",
    "        else:\n",
    "            best = min(y)\n",
    "            form = \"{:.2E}\"\n",
    "            logplot = True\n",
    "        # scale to resemble number of epochs instead of plot points\n",
    "        ticks_x = ticker.FuncFormatter(\n",
    "            lambda x, pos: \"{0:g}\".format(x * testlogger._every)\n",
    "        )\n",
    "        ax1.xaxis.set_major_formatter(ticks_x)\n",
    "        if logplot:\n",
    "            ax1.set_yscale(\"log\")\n",
    "        else:\n",
    "            ax1.set_yscale(\"linear\")\n",
    "        if where == \"valid\":\n",
    "            where = \"test\"\n",
    "        ax1.plot(\n",
    "            y, label=f\"{where}: {form.format(best)}\", linestyle=style, color=\"black\"\n",
    "        )\n",
    "        ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 50\n",
    "sampleids = np.random.choice(\n",
    "    np.arange(testdata.data.shape[0]), size=SAMPLE_SIZE, replace=False\n",
    ")\n",
    "sampledata = testdata.data[sampleids]\n",
    "samplepred = estimator.predict(sampledata)\n",
    "samplelabels = testdata.labels[sampleids]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "\n",
    "for i in range(samplelabels.shape[0]):\n",
    "    ax.plot(\n",
    "        [samplelabels[i, 0], samplepred[i, 0]],\n",
    "        [samplelabels[i, 1], samplepred[i, 1]],\n",
    "        marker=\"o\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "preds = estimator.predict(testdata)\n",
    "labels = testdata.labels\n",
    "distances = np.linalg.norm(preds - labels, axis=1, ord=2)\n",
    "\n",
    "ax.set_xlabel(\"distance (Euclidean)\")\n",
    "ax.set_ylabel(\"count\")\n",
    "ax.hist(distances, bins=50, color=\"black\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "label = traindata.labels\n",
    "pred = estimator.predict(traindata)\n",
    "\n",
    "ax.set_xlim(0, 30)\n",
    "ax.set_ylim(-35, -13)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "\n",
    "ax.scatter(label[:, 0], label[:, 1], color=\"black\", s=6, marker=\".\")\n",
    "ax.scatter(pred[:, 0], pred[:, 1], color=(0.7, 0.7, 0.7), s=6, marker=\".\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "pred = estimator.predict(blindtest)\n",
    "\n",
    "ax.set_xlim(0, 30)\n",
    "ax.set_ylim(-35, -13)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "\n",
    "ax.scatter(pred[:, 0], pred[:, 1], color=(0.7, 0.7, 0.7), s=6, marker=\".\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "fixed_rng = np.random.default_rng(123)\n",
    "\n",
    "n_tries = 30\n",
    "train_loss_avg = {\"MSE\": 0, \"MEE\": 0}\n",
    "test_loss_avg = {\"MSE\": 0, \"MEE\": 0}\n",
    "teststopper = TrainingThresholdStopping(estimator, early_stopping)\n",
    "for i in range(n_tries):\n",
    "    estimator.update_params(seed=fixed_rng.integers(0, sys.maxsize))\n",
    "    estimator.train(traindata, callback=teststopper, n_epochs=epochs)\n",
    "    train_res = estimator.evaluate(losses=losses, dataset=traindata)\n",
    "    test_res = estimator.evaluate(losses=losses, dataset=testdata)\n",
    "    print(f\"{i} / {n_tries}: {train_res}, {test_res}\")\n",
    "    for loss in losses:\n",
    "        train_loss_avg[loss] += train_res[loss]\n",
    "        test_loss_avg[loss] += test_res[loss]\n",
    "\n",
    "for loss in losses:\n",
    "    train_loss_avg[loss] = train_loss_avg[loss] / n_tries\n",
    "    test_loss_avg[loss] = test_loss_avg[loss] / n_tries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_loss_avg, test_loss_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5bd504499a3d325a7c1da9f8228712639636db49ae66a9009fa19a793144457f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
