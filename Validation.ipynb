{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce432db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from ddnn.nn import *\n",
    "from ddnn.data import *\n",
    "from ddnn.validation import *"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9adc196",
   "metadata": {},
   "source": [
    "class Logger:\n",
    "    def __init__(self, estimator: Estimator, losses: List[str], every: int = 1):\n",
    "        self._estimator = estimator\n",
    "        self._losses = losses\n",
    "        self._scores = []\n",
    "        self._every = every\n",
    "\n",
    "    def update_hp(self, hp_dict : Dict):\n",
    "        self._scores.append({\"hp\": hp_dict.copy(), \"folds\": []})\n",
    "\n",
    "    def update_fold(self, fold_dict : Dict):\n",
    "        self._vfold = fold_dict[\"test\"]\n",
    "        self._tfold = fold_dict[\"train\"]\n",
    "\n",
    "        current_hp_config = self._scores[-1]\n",
    "        current_hp_config[\"folds\"].append({\"train\":{},\"valid\":{}})\n",
    "\n",
    "        current_fold = current_hp_config[\"folds\"][-1]\n",
    "        for loss in self._losses:\n",
    "            current_fold[\"train\"][loss] = []\n",
    "            current_fold[\"valid\"][loss] = []\n",
    "\n",
    "    def __call__(self, records):\n",
    "        current_epoch = records[\"epoch\"]\n",
    "        if (current_epoch - 1) % self._every == 0:\n",
    "            dt = self._estimator.evaluate(self._losses, self._tfold)\n",
    "            dv = self._estimator.evaluate(self._losses, self._vfold)\n",
    "\n",
    "            current_train = self._scores[-1][\"folds\"][-1][\"train\"]\n",
    "            current_valid = self._scores[-1][\"folds\"][-1][\"valid\"]\n",
    "            \n",
    "            for loss in self._losses:\n",
    "                current_train[loss].append(dt[loss])\n",
    "                current_valid[loss].append(dv[loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c30a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetwork(\n",
    "    [\n",
    "        LinearLayer((8, 16)),\n",
    "        ActivationFunction(),\n",
    "        LinearLayer((16, 16)),\n",
    "        ActivationFunction(),\n",
    "        LinearLayer((16, 2)),\n",
    "    ]\n",
    ")\n",
    "estimator = Estimator(net) # fix to work without anything\n",
    "grid = {}\n",
    "grid[\"layers\"] = [[(4, \"ReLU\"), (1, \"logistic\")]]\n",
    "grid[\"learning_rate\"] = [0.5, 0.6]\n",
    "grid[\"momentum_coefficient\"] = [0.9]\n",
    "grid[\"optimizer\"] = [\"SGD\"]\n",
    "grid[\"loss\"] = [\"MSE\"]\n",
    "grid[\"l2_coefficient\"] = [1e-3, 1e-4, 1e-5]\n",
    "grid[\"batchsize\"] = [-1, 16]\n",
    "grid[\"weight_initializer\"] = [\"random_uniform\"]\n",
    "# grid['fan_mode'] = ['fan_in', 'fan_out']\n",
    "selector = GridSearch(estimator, grid, 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018eff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = read_ML_cup(\"train\")\n",
    "data = read_monks(1, \"train\")\n",
    "data = onehot_encoding(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2228dacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger(estimator, [\"MSE\", \"binary_accuracy\"], every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e5c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.k_fold(\n",
    "    data,\n",
    "    5,\n",
    "    n_epochs=2000,\n",
    "    loss_list=[\"MSE\"],\n",
    "    early_stopping=(10, 10),\n",
    "    seed=123,\n",
    "    on_fold_change=logger.update_fold,\n",
    "    on_hp_change=logger.update_hp,\n",
    "    training_callback=logger,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e675045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets.widgets import interact_manual, interact\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from textwrap import wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526a7f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "\n",
    "hps = [x[\"hp\"] for x in logger._scores]\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "@interact(\n",
    "    loss = logger._losses,\n",
    "    hyper = hps,\n",
    "    where = [\"train\", \"valid\"]\n",
    ")\n",
    "def plot_results(loss, hyper, where):\n",
    "    ys = [y[where][loss] for y in logger._scores[hps.index(hyper)][\"folds\"]]\n",
    "    if loss != \"binary_accuracy\":\n",
    "        bests = [min(y) for y in ys]\n",
    "        form = \"{:.2E}\"\n",
    "        logplot = True\n",
    "    else:\n",
    "        bests = [max(y) for y in ys]\n",
    "        form = \"{:.2}\"\n",
    "        logplot = False\n",
    "\n",
    "    ax.clear()\n",
    "    ax.set_title(\", \".join([f\"{k}={v}\" for k,v in hyper.items()]), wrap=True, fontsize=10)\n",
    "    # scale to resemble number of epochs instead of plot points\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x*logger._every))\n",
    "    ax.xaxis.set_major_formatter(ticks_x)\n",
    "    if logplot:\n",
    "        ax.set_yscale(\"log\")\n",
    "    else:\n",
    "        ax.set_yscale(\"linear\")\n",
    "    for y,best in zip(ys, bests):\n",
    "        ax.plot(y, label=f\"{form.format(best)}\")\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "840c151f",
   "metadata": {},
   "source": [
    "%matplotlib ipympl\n",
    "\n",
    "hps = [x[\"hp\"] for x in logger._scores]\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "@interact(\n",
    "    loss = logger._losses,\n",
    "    hyper = hps\n",
    ")\n",
    "def plot_results(loss, hyper, where):\n",
    "    yst = [y[where][loss] for y in logger._scores[hps.index(hyper)][\"folds\"]]\n",
    "    ysv = [y[where][loss] for y in logger._scores[hps.index(hyper)][\"folds\"]]\n",
    "    if loss != \"binary_accuracy\":\n",
    "        bests = [min(y) for y in ys]\n",
    "        form = \"{:.2E}\"\n",
    "        logplot = False\n",
    "    else:\n",
    "        bests = [max(y) for y in ys]\n",
    "        form = \"{:.2}\"\n",
    "        logplot = True\n",
    "\n",
    "    ax.clear()\n",
    "    ax.set_title(\" \".join([f\"{k}={v}\" for k,v in hyper.items()]), wrap=True, fontsize=10)\n",
    "    # scale to resemble number of epochs instead of plot points\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x*logger._every))\n",
    "    ax.xaxis.set_major_formatter(ticks_x)\n",
    "    if logplot:\n",
    "        ax.set_yscale(\"log\")\n",
    "    else:\n",
    "        ax.set_yscale(\"linear\")\n",
    "    for y,best in zip(ys, bests):\n",
    "        ax.plot(y, label=f\"{form.format(best)}\")\n",
    "    ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "29308c18330174df5d08dc27cbd59630723a13c381a5b5f57befcdc7a6962bd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
